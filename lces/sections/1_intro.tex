\vspace{-0.2cm}\section{Introduction}\vspace{-0.2cm}
Many physical, biological, and mathematical systems can be modeled by partial differential equations (PDEs).
Analytic solutions are rarely available for PDEs of practical importance; thus, computational methods to approximate PDE solutions are critical for many problems in science and engineering.
Finite element analysis (FEA) is one of the most widely used techniques for solving PDEs on spatial domains; the continuous problem is discretized and replaced by basis functions on a mesh.

The accuracy of FEA and related methods requires a sufficiently fine discrete approximation, i.e., finite element mesh.
Complicated domains can require fine meshes that make it prohibitively expensive to solve the PDE.
This problem is compounded for parameter identification or design optimization,
where the PDE must be repeatedly solved in the inner loop of a bi-level optimization problem.

An important domain where this challenge is particularly relevant is in modeling mechanical meta-materials.
Meta-materials are solids in which microstructure leads to rich spaces of macroscopic behavior, which can achieve electromagnetic and/or mechanical properties that are impossible with homogenous materials and traditional design approaches \citep{poddubny2013hyperbolic,cai2010optical,bertoldi2017flexible}.
We focus on the \emph{cellular} mechanical meta-materials proposed by \citet{overvelde2014relating}, which promise new high-performance materials for soft robotics and other domains (see Sec 3).
Simulation of these meta-materials is challenging due to the need to accurately capture microstructure and small-scale nonlinear elastic behavior.
Finite element methods have limited ability to scale to these problems, and automated meta-material design demands accurate, efficient approximate solutions to the associated PDE.

We develop a framework which exploits spatially local structure in large-scale optimization problems---here the minimization of energy as a function of meta-material displacements.
Only a small subset of material displacements are of interest, so we ``collapse out'' the remainder using a learned surrogate.
Given a component with substructure defined by local parameters, the surrogate produces an accurate proxy energy in terms of the displacement of the component boundary.
A single surrogate can be trained then used to predict energy in a larger solid by summing energies of sub-components.
This allows solving the PDE in a reduced basis of component boundaries by minimizing this sum.

Other methods exist for reducing the solution cost of large PDEs. One such is the boundary element method \citep{aliabadi2002boundary}, which as with our method "collapses out" the internal degrees of freedom in a PDE leaving a problem in terms of the solution on the boundary. Unlike our method, this is performed analytically and is typically only valid for linear PDEs. Our method might be seen as a \emph{learned} boundary element method for a particular parametric class of nonlinear PDEs. Another related line of work is homogenization. Whether micro-scale effects are modeled with fine-resolution FEM \citep{schroder2014numerical} or a neural network \citep{xue2020data}, homogenized models require a PDE formed of homogenous representative volume elements (RVEs), and are accurate only as the ratio between the size of the RVE and the size of the macro-scale problem tends to zero.

Some approaches amortize PDE solving more directly, using neural networks to map from PDE parameters to solutions \citep{zhu2019physics,nie2020stress} or constructing reduced bases via solving eigenvalue problems or interpolating between snapshots \citep{berkooz1993proper, chatterjee2000introduction}.
These approaches typically require solving full systems to produce training data.
Our framework uses the modular decomposition of energy to train surrogate models on data generated by querying the finite element "expert" on the energy in small components, avoiding performing FEA on large systems which are expensive to solve.
